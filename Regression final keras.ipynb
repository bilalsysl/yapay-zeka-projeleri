{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dff7ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e9586e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a21ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('istanbul.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e95ff9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1018ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dbdb2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fiyat</th>\n",
       "      <th>yas</th>\n",
       "      <th>kat</th>\n",
       "      <th>boyut</th>\n",
       "      <th>alan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>5</td>\n",
       "      <td>10. Kat</td>\n",
       "      <td>2 + 1</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32000</td>\n",
       "      <td>16</td>\n",
       "      <td>4. Kat</td>\n",
       "      <td>4 + 1</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15000</td>\n",
       "      <td>13</td>\n",
       "      <td>6. Kat</td>\n",
       "      <td>1 + 1</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35000</td>\n",
       "      <td>3</td>\n",
       "      <td>21 ve üzeri</td>\n",
       "      <td>1 + 1</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110000</td>\n",
       "      <td>11</td>\n",
       "      <td>Bahçe Katı</td>\n",
       "      <td>4 + 2</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>55000</td>\n",
       "      <td>50</td>\n",
       "      <td>4. Kat</td>\n",
       "      <td>4 + 2</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>19200</td>\n",
       "      <td>9</td>\n",
       "      <td>Ara Kat</td>\n",
       "      <td>2 + 1</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>8100</td>\n",
       "      <td>25</td>\n",
       "      <td>1. Kat</td>\n",
       "      <td>2 + 1</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>12000</td>\n",
       "      <td>9</td>\n",
       "      <td>1. Kat</td>\n",
       "      <td>1 + 1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>10000</td>\n",
       "      <td>2</td>\n",
       "      <td>3. Kat</td>\n",
       "      <td>Stüdyo</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fiyat  yas                                kat   boyut  alan\n",
       "0     30000    5                            10. Kat   2 + 1   115\n",
       "1     32000   16                             4. Kat   4 + 1   180\n",
       "2     15000   13                             6. Kat   1 + 1    85\n",
       "3     35000    3                        21 ve üzeri   1 + 1    90\n",
       "4    110000   11                         Bahçe Katı   4 + 2   470\n",
       "..      ...  ...                                ...     ...   ...\n",
       "235   55000   50                             4. Kat   4 + 2   310\n",
       "236   19200    9                            Ara Kat   2 + 1   110\n",
       "237    8100   25                             1. Kat   2 + 1    85\n",
       "238   12000    9                             1. Kat   1 + 1    60\n",
       "239   10000    2                             3. Kat  Stüdyo    55\n",
       "\n",
       "[240 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1149abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.get_dummies(df,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71cc7ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('fiyat',axis=1)\n",
    "y=df['fiyat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e670730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52380bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y, test_size=0.2,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71d5ca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(81,activation='relu'))\n",
    "model.add(Dense(40,activation='relu'))\n",
    "model.add(Dense(27,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(5,activation='relu'))\n",
    "model.add(Dense(3,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='Adam',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cacbbf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/450\n",
      "2/2 [==============================] - 1s 128ms/step - loss: 777207360.0000 - val_loss: 3602385920.0000\n",
      "Epoch 2/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 777021760.0000 - val_loss: 3602040064.0000\n",
      "Epoch 3/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 776905216.0000 - val_loss: 3601747200.0000\n",
      "Epoch 4/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 776826176.0000 - val_loss: 3601575168.0000\n",
      "Epoch 5/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 776767744.0000 - val_loss: 3601351680.0000\n",
      "Epoch 6/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 776705216.0000 - val_loss: 3601178624.0000\n",
      "Epoch 7/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 776645888.0000 - val_loss: 3600982272.0000\n",
      "Epoch 8/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 776573504.0000 - val_loss: 3600747264.0000\n",
      "Epoch 9/450\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 776499264.0000 - val_loss: 3600522496.0000\n",
      "Epoch 10/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 776414464.0000 - val_loss: 3600269568.0000\n",
      "Epoch 11/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 776319552.0000 - val_loss: 3599970048.0000\n",
      "Epoch 12/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 776211968.0000 - val_loss: 3599613952.0000\n",
      "Epoch 13/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 776095424.0000 - val_loss: 3599207168.0000\n",
      "Epoch 14/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 775955456.0000 - val_loss: 3598742272.0000\n",
      "Epoch 15/450\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 775791808.0000 - val_loss: 3598230272.0000\n",
      "Epoch 16/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 775615296.0000 - val_loss: 3597625344.0000\n",
      "Epoch 17/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 775392768.0000 - val_loss: 3596939008.0000\n",
      "Epoch 18/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 775152064.0000 - val_loss: 3596145408.0000\n",
      "Epoch 19/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 774876480.0000 - val_loss: 3595223296.0000\n",
      "Epoch 20/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 774551552.0000 - val_loss: 3594152704.0000\n",
      "Epoch 21/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 774187584.0000 - val_loss: 3592912896.0000\n",
      "Epoch 22/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 773771072.0000 - val_loss: 3591528192.0000\n",
      "Epoch 23/450\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 773299136.0000 - val_loss: 3589911808.0000\n",
      "Epoch 24/450\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 772674048.0000 - val_loss: 3588069376.0000\n",
      "Epoch 25/450\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 772078912.0000 - val_loss: 3585961216.0000\n",
      "Epoch 26/450\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 771291840.0000 - val_loss: 3583529216.0000\n",
      "Epoch 27/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 770518208.0000 - val_loss: 3580734720.0000\n",
      "Epoch 28/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 769478656.0000 - val_loss: 3577563136.0000\n",
      "Epoch 29/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 768294464.0000 - val_loss: 3573956352.0000\n",
      "Epoch 30/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 767041600.0000 - val_loss: 3569861888.0000\n",
      "Epoch 31/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 765706560.0000 - val_loss: 3565288192.0000\n",
      "Epoch 32/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 764072960.0000 - val_loss: 3560101120.0000\n",
      "Epoch 33/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 762321216.0000 - val_loss: 3554260992.0000\n",
      "Epoch 34/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 760272320.0000 - val_loss: 3547712768.0000\n",
      "Epoch 35/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 757970112.0000 - val_loss: 3540322048.0000\n",
      "Epoch 36/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 755488768.0000 - val_loss: 3532096256.0000\n",
      "Epoch 37/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 752569088.0000 - val_loss: 3522923520.0000\n",
      "Epoch 38/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 749288768.0000 - val_loss: 3512595712.0000\n",
      "Epoch 39/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 745771072.0000 - val_loss: 3501018880.0000\n",
      "Epoch 40/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 741824320.0000 - val_loss: 3488140288.0000\n",
      "Epoch 41/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 736954176.0000 - val_loss: 3473793024.0000\n",
      "Epoch 42/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 732287808.0000 - val_loss: 3457659648.0000\n",
      "Epoch 43/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 726599616.0000 - val_loss: 3439704320.0000\n",
      "Epoch 44/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 720593728.0000 - val_loss: 3419791104.0000\n",
      "Epoch 45/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 713594560.0000 - val_loss: 3397741824.0000\n",
      "Epoch 46/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 705756416.0000 - val_loss: 3373304832.0000\n",
      "Epoch 47/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 697816512.0000 - val_loss: 3346148608.0000\n",
      "Epoch 48/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 688109632.0000 - val_loss: 3316237312.0000\n",
      "Epoch 49/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 677508864.0000 - val_loss: 3283226880.0000\n",
      "Epoch 50/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 667319040.0000 - val_loss: 3246740224.0000\n",
      "Epoch 51/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 654874688.0000 - val_loss: 3206915840.0000\n",
      "Epoch 52/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 641385216.0000 - val_loss: 3163326464.0000\n",
      "Epoch 53/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 626703808.0000 - val_loss: 3115633664.0000\n",
      "Epoch 54/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 611066880.0000 - val_loss: 3063514880.0000\n",
      "Epoch 55/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 595386880.0000 - val_loss: 3006944000.0000\n",
      "Epoch 56/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 577553856.0000 - val_loss: 2946469888.0000\n",
      "Epoch 57/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 557304320.0000 - val_loss: 2881680640.0000\n",
      "Epoch 58/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 538423424.0000 - val_loss: 2811811072.0000\n",
      "Epoch 59/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 515403232.0000 - val_loss: 2737381376.0000\n",
      "Epoch 60/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 493850016.0000 - val_loss: 2657144064.0000\n",
      "Epoch 61/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 469896448.0000 - val_loss: 2571683584.0000\n",
      "Epoch 62/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 446873216.0000 - val_loss: 2481099008.0000\n",
      "Epoch 63/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 421071616.0000 - val_loss: 2386445056.0000\n",
      "Epoch 64/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 395827104.0000 - val_loss: 2287330560.0000\n",
      "Epoch 65/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 369306240.0000 - val_loss: 2184454400.0000\n",
      "Epoch 66/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 344603392.0000 - val_loss: 2077733760.0000\n",
      "Epoch 67/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 323640832.0000 - val_loss: 1969024000.0000\n",
      "Epoch 68/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 299249696.0000 - val_loss: 1862061056.0000\n",
      "Epoch 69/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 280541280.0000 - val_loss: 1756449280.0000\n",
      "Epoch 70/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 262531184.0000 - val_loss: 1655332480.0000\n",
      "Epoch 71/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 19ms/step - loss: 245123120.0000 - val_loss: 1560504192.0000\n",
      "Epoch 72/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 237208944.0000 - val_loss: 1469092864.0000\n",
      "Epoch 73/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 232355728.0000 - val_loss: 1387981312.0000\n",
      "Epoch 74/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 227074032.0000 - val_loss: 1322351488.0000\n",
      "Epoch 75/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 225211776.0000 - val_loss: 1269839232.0000\n",
      "Epoch 76/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 225855168.0000 - val_loss: 1228515584.0000\n",
      "Epoch 77/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 228065424.0000 - val_loss: 1197640320.0000\n",
      "Epoch 78/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 229635088.0000 - val_loss: 1178447360.0000\n",
      "Epoch 79/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 231652912.0000 - val_loss: 1167997440.0000\n",
      "Epoch 80/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 231829120.0000 - val_loss: 1170172160.0000\n",
      "Epoch 81/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 231311504.0000 - val_loss: 1176481920.0000\n",
      "Epoch 82/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 229927280.0000 - val_loss: 1185316224.0000\n",
      "Epoch 83/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 228493248.0000 - val_loss: 1203715712.0000\n",
      "Epoch 84/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 226781552.0000 - val_loss: 1226161920.0000\n",
      "Epoch 85/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 224811728.0000 - val_loss: 1250029824.0000\n",
      "Epoch 86/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 225245392.0000 - val_loss: 1275487744.0000\n",
      "Epoch 87/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 223097296.0000 - val_loss: 1293052800.0000\n",
      "Epoch 88/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 222927312.0000 - val_loss: 1310068096.0000\n",
      "Epoch 89/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 223005056.0000 - val_loss: 1324153728.0000\n",
      "Epoch 90/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 222891088.0000 - val_loss: 1333268352.0000\n",
      "Epoch 91/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 222848192.0000 - val_loss: 1338681216.0000\n",
      "Epoch 92/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 222886384.0000 - val_loss: 1341335936.0000\n",
      "Epoch 93/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 222807120.0000 - val_loss: 1339731328.0000\n",
      "Epoch 94/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 222585264.0000 - val_loss: 1334124160.0000\n",
      "Epoch 95/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 222302256.0000 - val_loss: 1327727360.0000\n",
      "Epoch 96/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 222162112.0000 - val_loss: 1320990720.0000\n",
      "Epoch 97/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 221792832.0000 - val_loss: 1316232704.0000\n",
      "Epoch 98/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 221559056.0000 - val_loss: 1312118912.0000\n",
      "Epoch 99/450\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 221310208.0000 - val_loss: 1308170496.0000\n",
      "Epoch 100/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 221128256.0000 - val_loss: 1303559552.0000\n",
      "Epoch 101/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 220906448.0000 - val_loss: 1298839680.0000\n",
      "Epoch 102/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 220784048.0000 - val_loss: 1293736064.0000\n",
      "Epoch 103/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 220628608.0000 - val_loss: 1290303104.0000\n",
      "Epoch 104/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 220361520.0000 - val_loss: 1289176192.0000\n",
      "Epoch 105/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 220224624.0000 - val_loss: 1287530496.0000\n",
      "Epoch 106/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 220052752.0000 - val_loss: 1286077312.0000\n",
      "Epoch 107/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 219973440.0000 - val_loss: 1282884224.0000\n",
      "Epoch 108/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 219789648.0000 - val_loss: 1281627520.0000\n",
      "Epoch 109/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 219542160.0000 - val_loss: 1276618624.0000\n",
      "Epoch 110/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 219444224.0000 - val_loss: 1271543424.0000\n",
      "Epoch 111/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 219247296.0000 - val_loss: 1261583488.0000\n",
      "Epoch 112/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 218961744.0000 - val_loss: 1254317184.0000\n",
      "Epoch 113/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 218981968.0000 - val_loss: 1247293056.0000\n",
      "Epoch 114/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 218689904.0000 - val_loss: 1243959168.0000\n",
      "Epoch 115/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 218689584.0000 - val_loss: 1239805440.0000\n",
      "Epoch 116/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 218373504.0000 - val_loss: 1240460160.0000\n",
      "Epoch 117/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 218172976.0000 - val_loss: 1241929984.0000\n",
      "Epoch 118/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 218078608.0000 - val_loss: 1245182720.0000\n",
      "Epoch 119/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 217807984.0000 - val_loss: 1246172032.0000\n",
      "Epoch 120/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 217897968.0000 - val_loss: 1247814528.0000\n",
      "Epoch 121/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 217450064.0000 - val_loss: 1244047488.0000\n",
      "Epoch 122/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 217299456.0000 - val_loss: 1238532608.0000\n",
      "Epoch 123/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 217269760.0000 - val_loss: 1230318080.0000\n",
      "Epoch 124/450\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 217105840.0000 - val_loss: 1225618048.0000\n",
      "Epoch 125/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 216925104.0000 - val_loss: 1217304576.0000\n",
      "Epoch 126/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 216832688.0000 - val_loss: 1211622784.0000\n",
      "Epoch 127/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 216759168.0000 - val_loss: 1207365504.0000\n",
      "Epoch 128/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 216784656.0000 - val_loss: 1203084928.0000\n",
      "Epoch 129/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 216724736.0000 - val_loss: 1203848320.0000\n",
      "Epoch 130/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 216359104.0000 - val_loss: 1201828608.0000\n",
      "Epoch 131/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 216239376.0000 - val_loss: 1202740352.0000\n",
      "Epoch 132/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 216099712.0000 - val_loss: 1203048192.0000\n",
      "Epoch 133/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 215779760.0000 - val_loss: 1208841984.0000\n",
      "Epoch 134/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 215489600.0000 - val_loss: 1215274624.0000\n",
      "Epoch 135/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 215196304.0000 - val_loss: 1222712704.0000\n",
      "Epoch 136/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 214954448.0000 - val_loss: 1233581312.0000\n",
      "Epoch 137/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 214963088.0000 - val_loss: 1244274688.0000\n",
      "Epoch 138/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 214830832.0000 - val_loss: 1251983488.0000\n",
      "Epoch 139/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 215201360.0000 - val_loss: 1257851264.0000\n",
      "Epoch 140/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 214914224.0000 - val_loss: 1256533632.0000\n",
      "Epoch 141/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 19ms/step - loss: 214742288.0000 - val_loss: 1256278400.0000\n",
      "Epoch 142/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 214634928.0000 - val_loss: 1256332928.0000\n",
      "Epoch 143/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 214513552.0000 - val_loss: 1252889856.0000\n",
      "Epoch 144/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 214288816.0000 - val_loss: 1245813248.0000\n",
      "Epoch 145/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 214351024.0000 - val_loss: 1236804480.0000\n",
      "Epoch 146/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 213978624.0000 - val_loss: 1231384448.0000\n",
      "Epoch 147/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 213765168.0000 - val_loss: 1227541504.0000\n",
      "Epoch 148/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 213697104.0000 - val_loss: 1224158848.0000\n",
      "Epoch 149/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 213507584.0000 - val_loss: 1222671488.0000\n",
      "Epoch 150/450\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 213510352.0000 - val_loss: 1219121664.0000\n",
      "Epoch 151/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 213249664.0000 - val_loss: 1219016576.0000\n",
      "Epoch 152/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 213308992.0000 - val_loss: 1219182080.0000\n",
      "Epoch 153/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 213059248.0000 - val_loss: 1214008192.0000\n",
      "Epoch 154/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 212861232.0000 - val_loss: 1210353792.0000\n",
      "Epoch 155/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 212740944.0000 - val_loss: 1206361728.0000\n",
      "Epoch 156/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 212667408.0000 - val_loss: 1202587008.0000\n",
      "Epoch 157/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 212524544.0000 - val_loss: 1195481728.0000\n",
      "Epoch 158/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 212440896.0000 - val_loss: 1190711424.0000\n",
      "Epoch 159/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 212340208.0000 - val_loss: 1188766976.0000\n",
      "Epoch 160/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 212172992.0000 - val_loss: 1190044288.0000\n",
      "Epoch 161/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 212019504.0000 - val_loss: 1193583616.0000\n",
      "Epoch 162/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 211899856.0000 - val_loss: 1198266240.0000\n",
      "Epoch 163/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 211764096.0000 - val_loss: 1201664768.0000\n",
      "Epoch 164/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 211702096.0000 - val_loss: 1204027520.0000\n",
      "Epoch 165/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 211570128.0000 - val_loss: 1204399232.0000\n",
      "Epoch 166/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 211475760.0000 - val_loss: 1205447296.0000\n",
      "Epoch 167/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 211406640.0000 - val_loss: 1205369216.0000\n",
      "Epoch 168/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 211273600.0000 - val_loss: 1206980992.0000\n",
      "Epoch 169/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 211365328.0000 - val_loss: 1206214016.0000\n",
      "Epoch 170/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 211271632.0000 - val_loss: 1199648256.0000\n",
      "Epoch 171/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 210936240.0000 - val_loss: 1196738688.0000\n",
      "Epoch 172/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 210827136.0000 - val_loss: 1191672448.0000\n",
      "Epoch 173/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 210828208.0000 - val_loss: 1187467008.0000\n",
      "Epoch 174/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 210603568.0000 - val_loss: 1186800000.0000\n",
      "Epoch 175/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 210542000.0000 - val_loss: 1186768640.0000\n",
      "Epoch 176/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 210390288.0000 - val_loss: 1184236032.0000\n",
      "Epoch 177/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 210400816.0000 - val_loss: 1181216256.0000\n",
      "Epoch 178/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 210122800.0000 - val_loss: 1173348224.0000\n",
      "Epoch 179/450\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 210365488.0000 - val_loss: 1165055104.0000\n",
      "Epoch 180/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 210037568.0000 - val_loss: 1162449408.0000\n",
      "Epoch 181/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 210152512.0000 - val_loss: 1161257344.0000\n",
      "Epoch 182/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 210074880.0000 - val_loss: 1165801216.0000\n",
      "Epoch 183/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 210151504.0000 - val_loss: 1165493248.0000\n",
      "Epoch 184/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 209653056.0000 - val_loss: 1157656576.0000\n",
      "Epoch 185/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 209525424.0000 - val_loss: 1152817792.0000\n",
      "Epoch 186/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 209481968.0000 - val_loss: 1146538880.0000\n",
      "Epoch 187/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 209427536.0000 - val_loss: 1143139328.0000\n",
      "Epoch 188/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 209412944.0000 - val_loss: 1142225792.0000\n",
      "Epoch 189/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 209499088.0000 - val_loss: 1140168576.0000\n",
      "Epoch 190/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 209121136.0000 - val_loss: 1145358848.0000\n",
      "Epoch 191/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 208966960.0000 - val_loss: 1154359296.0000\n",
      "Epoch 192/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 208768256.0000 - val_loss: 1161759872.0000\n",
      "Epoch 193/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 208683120.0000 - val_loss: 1167895168.0000\n",
      "Epoch 194/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 208620224.0000 - val_loss: 1171913728.0000\n",
      "Epoch 195/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 208408880.0000 - val_loss: 1180211200.0000\n",
      "Epoch 196/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 209210624.0000 - val_loss: 1190780032.0000\n",
      "Epoch 197/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 208571904.0000 - val_loss: 1191070464.0000\n",
      "Epoch 198/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 208642544.0000 - val_loss: 1188091904.0000\n",
      "Epoch 199/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 208365360.0000 - val_loss: 1178189184.0000\n",
      "Epoch 200/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 208143920.0000 - val_loss: 1168759936.0000\n",
      "Epoch 201/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 208007232.0000 - val_loss: 1159738752.0000\n",
      "Epoch 202/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 207917392.0000 - val_loss: 1151985152.0000\n",
      "Epoch 203/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 207866368.0000 - val_loss: 1146467968.0000\n",
      "Epoch 204/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 207729936.0000 - val_loss: 1143425408.0000\n",
      "Epoch 205/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 207691344.0000 - val_loss: 1140614784.0000\n",
      "Epoch 206/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 207618224.0000 - val_loss: 1139787776.0000\n",
      "Epoch 207/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 207540992.0000 - val_loss: 1139376640.0000\n",
      "Epoch 208/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 207524656.0000 - val_loss: 1137264768.0000\n",
      "Epoch 209/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 207531344.0000 - val_loss: 1131777024.0000\n",
      "Epoch 210/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 207358160.0000 - val_loss: 1131234560.0000\n",
      "Epoch 211/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 19ms/step - loss: 207238288.0000 - val_loss: 1133592192.0000\n",
      "Epoch 212/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 207207040.0000 - val_loss: 1136023552.0000\n",
      "Epoch 213/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 207295824.0000 - val_loss: 1135903360.0000\n",
      "Epoch 214/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 207070320.0000 - val_loss: 1130187392.0000\n",
      "Epoch 215/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 207010992.0000 - val_loss: 1128799104.0000\n",
      "Epoch 216/450\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 206825808.0000 - val_loss: 1131883520.0000\n",
      "Epoch 217/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 206686512.0000 - val_loss: 1138123904.0000\n",
      "Epoch 218/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 206557264.0000 - val_loss: 1148169600.0000\n",
      "Epoch 219/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 206531248.0000 - val_loss: 1157188096.0000\n",
      "Epoch 220/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 206583936.0000 - val_loss: 1164713600.0000\n",
      "Epoch 221/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 206489296.0000 - val_loss: 1176461184.0000\n",
      "Epoch 222/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 206719888.0000 - val_loss: 1186283392.0000\n",
      "Epoch 223/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 207188528.0000 - val_loss: 1192676992.0000\n",
      "Epoch 224/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 207179184.0000 - val_loss: 1191605888.0000\n",
      "Epoch 225/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 207048688.0000 - val_loss: 1190232320.0000\n",
      "Epoch 226/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 206931648.0000 - val_loss: 1184527616.0000\n",
      "Epoch 227/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 207079360.0000 - val_loss: 1175162496.0000\n",
      "Epoch 228/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 206617264.0000 - val_loss: 1169501824.0000\n",
      "Epoch 229/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 206304496.0000 - val_loss: 1165483520.0000\n",
      "Epoch 230/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 206202432.0000 - val_loss: 1159919872.0000\n",
      "Epoch 231/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 206206080.0000 - val_loss: 1153634816.0000\n",
      "Epoch 232/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 205967888.0000 - val_loss: 1139085696.0000\n",
      "Epoch 233/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 205683584.0000 - val_loss: 1127458304.0000\n",
      "Epoch 234/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 205463376.0000 - val_loss: 1117379200.0000\n",
      "Epoch 235/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 205335344.0000 - val_loss: 1104537600.0000\n",
      "Epoch 236/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 206145040.0000 - val_loss: 1090944512.0000\n",
      "Epoch 237/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 205858864.0000 - val_loss: 1086726784.0000\n",
      "Epoch 238/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 205715520.0000 - val_loss: 1088227456.0000\n",
      "Epoch 239/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 205707984.0000 - val_loss: 1091211776.0000\n",
      "Epoch 240/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 205496656.0000 - val_loss: 1100633600.0000\n",
      "Epoch 241/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 205358592.0000 - val_loss: 1108389120.0000\n",
      "Epoch 242/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 205182720.0000 - val_loss: 1113070208.0000\n",
      "Epoch 243/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 205025840.0000 - val_loss: 1115658112.0000\n",
      "Epoch 244/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 205026448.0000 - val_loss: 1120494592.0000\n",
      "Epoch 245/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 204914176.0000 - val_loss: 1122706304.0000\n",
      "Epoch 246/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 204851776.0000 - val_loss: 1126942976.0000\n",
      "Epoch 247/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 205087040.0000 - val_loss: 1133556992.0000\n",
      "Epoch 248/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 204880704.0000 - val_loss: 1133889408.0000\n",
      "Epoch 249/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 204789808.0000 - val_loss: 1130852864.0000\n",
      "Epoch 250/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 204850432.0000 - val_loss: 1126740352.0000\n",
      "Epoch 251/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 204643888.0000 - val_loss: 1125448064.0000\n",
      "Epoch 252/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 204647632.0000 - val_loss: 1122664832.0000\n",
      "Epoch 253/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 204561712.0000 - val_loss: 1121854080.0000\n",
      "Epoch 254/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 204540912.0000 - val_loss: 1122946560.0000\n",
      "Epoch 255/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 204609664.0000 - val_loss: 1126679040.0000\n",
      "Epoch 256/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 204483536.0000 - val_loss: 1125235072.0000\n",
      "Epoch 257/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 204386256.0000 - val_loss: 1125195520.0000\n",
      "Epoch 258/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 204415152.0000 - val_loss: 1123159552.0000\n",
      "Epoch 259/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 204311792.0000 - val_loss: 1123626112.0000\n",
      "Epoch 260/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 204241136.0000 - val_loss: 1125636736.0000\n",
      "Epoch 261/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 204282800.0000 - val_loss: 1125706752.0000\n",
      "Epoch 262/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 204168192.0000 - val_loss: 1121462656.0000\n",
      "Epoch 263/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 204071936.0000 - val_loss: 1116093824.0000\n",
      "Epoch 264/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 203973120.0000 - val_loss: 1108703360.0000\n",
      "Epoch 265/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 204073392.0000 - val_loss: 1101671936.0000\n",
      "Epoch 266/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 203860496.0000 - val_loss: 1098364416.0000\n",
      "Epoch 267/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 204066608.0000 - val_loss: 1094478208.0000\n",
      "Epoch 268/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 203784576.0000 - val_loss: 1096187392.0000\n",
      "Epoch 269/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 203739264.0000 - val_loss: 1098319104.0000\n",
      "Epoch 270/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 203847104.0000 - val_loss: 1099223680.0000\n",
      "Epoch 271/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 203633584.0000 - val_loss: 1095402496.0000\n",
      "Epoch 272/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 203596432.0000 - val_loss: 1091875200.0000\n",
      "Epoch 273/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 203603840.0000 - val_loss: 1089167744.0000\n",
      "Epoch 274/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 203516672.0000 - val_loss: 1089138048.0000\n",
      "Epoch 275/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 203899184.0000 - val_loss: 1088410112.0000\n",
      "Epoch 276/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 203395584.0000 - val_loss: 1079785344.0000\n",
      "Epoch 277/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 203603280.0000 - val_loss: 1073203520.0000\n",
      "Epoch 278/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 203445568.0000 - val_loss: 1072194048.0000\n",
      "Epoch 279/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 203401664.0000 - val_loss: 1073984512.0000\n",
      "Epoch 280/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 203278848.0000 - val_loss: 1079401344.0000\n",
      "Epoch 281/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step - loss: 203175344.0000 - val_loss: 1086475904.0000\n",
      "Epoch 282/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 203032848.0000 - val_loss: 1098035712.0000\n",
      "Epoch 283/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 203881552.0000 - val_loss: 1108413824.0000\n",
      "Epoch 284/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 203225024.0000 - val_loss: 1108810112.0000\n",
      "Epoch 285/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 203130752.0000 - val_loss: 1111378816.0000\n",
      "Epoch 286/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 203306496.0000 - val_loss: 1113169536.0000\n",
      "Epoch 287/450\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 203284608.0000 - val_loss: 1109283584.0000\n",
      "Epoch 288/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 203114256.0000 - val_loss: 1108485120.0000\n",
      "Epoch 289/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 203056080.0000 - val_loss: 1109169024.0000\n",
      "Epoch 290/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 202994800.0000 - val_loss: 1106343424.0000\n",
      "Epoch 291/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 202919408.0000 - val_loss: 1101852416.0000\n",
      "Epoch 292/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 203211696.0000 - val_loss: 1095392256.0000\n",
      "Epoch 293/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 202788688.0000 - val_loss: 1094441856.0000\n",
      "Epoch 294/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 202743168.0000 - val_loss: 1091043840.0000\n",
      "Epoch 295/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 202686544.0000 - val_loss: 1087856128.0000\n",
      "Epoch 296/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 202641936.0000 - val_loss: 1084623872.0000\n",
      "Epoch 297/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 202630704.0000 - val_loss: 1080012928.0000\n",
      "Epoch 298/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 202527616.0000 - val_loss: 1071329536.0000\n",
      "Epoch 299/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 202761984.0000 - val_loss: 1064021952.0000\n",
      "Epoch 300/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 202873648.0000 - val_loss: 1062648768.0000\n",
      "Epoch 301/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 202501392.0000 - val_loss: 1068696384.0000\n",
      "Epoch 302/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 202441456.0000 - val_loss: 1075009664.0000\n",
      "Epoch 303/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 202480176.0000 - val_loss: 1080176128.0000\n",
      "Epoch 304/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 202354304.0000 - val_loss: 1082358144.0000\n",
      "Epoch 305/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 202331648.0000 - val_loss: 1084229120.0000\n",
      "Epoch 306/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 202410800.0000 - val_loss: 1085279744.0000\n",
      "Epoch 307/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 202288176.0000 - val_loss: 1082217472.0000\n",
      "Epoch 308/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 202421360.0000 - val_loss: 1079444224.0000\n",
      "Epoch 309/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 202200704.0000 - val_loss: 1081068928.0000\n",
      "Epoch 310/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 202240784.0000 - val_loss: 1081993216.0000\n",
      "Epoch 311/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 202175504.0000 - val_loss: 1079816064.0000\n",
      "Epoch 312/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 202125584.0000 - val_loss: 1078546432.0000\n",
      "Epoch 313/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 202107440.0000 - val_loss: 1077023232.0000\n",
      "Epoch 314/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 202094160.0000 - val_loss: 1076452096.0000\n",
      "Epoch 315/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 202062512.0000 - val_loss: 1073172928.0000\n",
      "Epoch 316/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 202179056.0000 - val_loss: 1071947072.0000\n",
      "Epoch 317/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 202123504.0000 - val_loss: 1075504000.0000\n",
      "Epoch 318/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 202019920.0000 - val_loss: 1074649472.0000\n",
      "Epoch 319/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 201996976.0000 - val_loss: 1076606976.0000\n",
      "Epoch 320/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 201896576.0000 - val_loss: 1075189632.0000\n",
      "Epoch 321/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 201936128.0000 - val_loss: 1072611008.0000\n",
      "Epoch 322/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 201932080.0000 - val_loss: 1065835840.0000\n",
      "Epoch 323/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 201871376.0000 - val_loss: 1062037184.0000\n",
      "Epoch 324/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 201863296.0000 - val_loss: 1053969408.0000\n",
      "Epoch 325/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 201842064.0000 - val_loss: 1049800704.0000\n",
      "Epoch 326/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 201787696.0000 - val_loss: 1048853760.0000\n",
      "Epoch 327/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 201809168.0000 - val_loss: 1048011712.0000\n",
      "Epoch 328/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 201778640.0000 - val_loss: 1045197568.0000\n",
      "Epoch 329/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 201777584.0000 - val_loss: 1045812288.0000\n",
      "Epoch 330/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 201681792.0000 - val_loss: 1050733056.0000\n",
      "Epoch 331/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 201897040.0000 - val_loss: 1059514048.0000\n",
      "Epoch 332/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 201620464.0000 - val_loss: 1062640320.0000\n",
      "Epoch 333/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 201508944.0000 - val_loss: 1062998080.0000\n",
      "Epoch 334/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 201485632.0000 - val_loss: 1063084736.0000\n",
      "Epoch 335/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 201465216.0000 - val_loss: 1062040896.0000\n",
      "Epoch 336/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 201432576.0000 - val_loss: 1059473984.0000\n",
      "Epoch 337/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 201513872.0000 - val_loss: 1055028480.0000\n",
      "Epoch 338/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 201391408.0000 - val_loss: 1054513920.0000\n",
      "Epoch 339/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 201379504.0000 - val_loss: 1055445824.0000\n",
      "Epoch 340/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 201441536.0000 - val_loss: 1054271680.0000\n",
      "Epoch 341/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 201277488.0000 - val_loss: 1048527168.0000\n",
      "Epoch 342/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 201253056.0000 - val_loss: 1043456704.0000\n",
      "Epoch 343/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 201314560.0000 - val_loss: 1038012608.0000\n",
      "Epoch 344/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 201364144.0000 - val_loss: 1029312832.0000\n",
      "Epoch 345/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 201358976.0000 - val_loss: 1024779328.0000\n",
      "Epoch 346/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 201489072.0000 - val_loss: 1020549952.0000\n",
      "Epoch 347/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 201473536.0000 - val_loss: 1020859584.0000\n",
      "Epoch 348/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 201441488.0000 - val_loss: 1023729728.0000\n",
      "Epoch 349/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 201387136.0000 - val_loss: 1026919488.0000\n",
      "Epoch 350/450\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 201250816.0000 - val_loss: 1029301760.0000\n",
      "Epoch 351/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step - loss: 201315328.0000 - val_loss: 1034745664.0000\n",
      "Epoch 352/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 200867392.0000 - val_loss: 1047968320.0000\n",
      "Epoch 353/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 200923568.0000 - val_loss: 1064358592.0000\n",
      "Epoch 354/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 200933760.0000 - val_loss: 1077661056.0000\n",
      "Epoch 355/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 201220608.0000 - val_loss: 1088030080.0000\n",
      "Epoch 356/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 201307984.0000 - val_loss: 1093450624.0000\n",
      "Epoch 357/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 201412400.0000 - val_loss: 1099729024.0000\n",
      "Epoch 358/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 201750016.0000 - val_loss: 1102267264.0000\n",
      "Epoch 359/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 201683792.0000 - val_loss: 1097161728.0000\n",
      "Epoch 360/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 201575152.0000 - val_loss: 1091913600.0000\n",
      "Epoch 361/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 201397200.0000 - val_loss: 1087521664.0000\n",
      "Epoch 362/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 201291520.0000 - val_loss: 1082953088.0000\n",
      "Epoch 363/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 201024592.0000 - val_loss: 1071831104.0000\n",
      "Epoch 364/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 200741824.0000 - val_loss: 1058719744.0000\n",
      "Epoch 365/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200961360.0000 - val_loss: 1040722624.0000\n",
      "Epoch 366/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 200911312.0000 - val_loss: 1028340928.0000\n",
      "Epoch 367/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200860976.0000 - val_loss: 1021424448.0000\n",
      "Epoch 368/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 201069248.0000 - val_loss: 1018398144.0000\n",
      "Epoch 369/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 200939632.0000 - val_loss: 1021593024.0000\n",
      "Epoch 370/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200828656.0000 - val_loss: 1024373568.0000\n",
      "Epoch 371/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200805936.0000 - val_loss: 1029478976.0000\n",
      "Epoch 372/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 200675344.0000 - val_loss: 1033442496.0000\n",
      "Epoch 373/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200824512.0000 - val_loss: 1038171648.0000\n",
      "Epoch 374/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200650800.0000 - val_loss: 1038841152.0000\n",
      "Epoch 375/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 200571472.0000 - val_loss: 1043076288.0000\n",
      "Epoch 376/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200542160.0000 - val_loss: 1046674624.0000\n",
      "Epoch 377/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200718464.0000 - val_loss: 1052516032.0000\n",
      "Epoch 378/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200550544.0000 - val_loss: 1053019200.0000\n",
      "Epoch 379/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200518192.0000 - val_loss: 1051512256.0000\n",
      "Epoch 380/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200494416.0000 - val_loss: 1049879232.0000\n",
      "Epoch 381/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 200514000.0000 - val_loss: 1048366912.0000\n",
      "Epoch 382/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200446896.0000 - val_loss: 1048888256.0000\n",
      "Epoch 383/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 200498256.0000 - val_loss: 1050128384.0000\n",
      "Epoch 384/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200495696.0000 - val_loss: 1054426048.0000\n",
      "Epoch 385/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200439504.0000 - val_loss: 1054907584.0000\n",
      "Epoch 386/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200534896.0000 - val_loss: 1053815488.0000\n",
      "Epoch 387/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 200489776.0000 - val_loss: 1056410624.0000\n",
      "Epoch 388/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 200356112.0000 - val_loss: 1063140672.0000\n",
      "Epoch 389/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200463936.0000 - val_loss: 1071739200.0000\n",
      "Epoch 390/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200561072.0000 - val_loss: 1076956160.0000\n",
      "Epoch 391/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 200713856.0000 - val_loss: 1082818560.0000\n",
      "Epoch 392/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 201211856.0000 - val_loss: 1083278080.0000\n",
      "Epoch 393/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200729920.0000 - val_loss: 1072907008.0000\n",
      "Epoch 394/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 200631680.0000 - val_loss: 1062002176.0000\n",
      "Epoch 395/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 200257664.0000 - val_loss: 1053090240.0000\n",
      "Epoch 396/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200053184.0000 - val_loss: 1040601280.0000\n",
      "Epoch 397/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 200035280.0000 - val_loss: 1025578176.0000\n",
      "Epoch 398/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 201084912.0000 - val_loss: 1013143872.0000\n",
      "Epoch 399/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 200392368.0000 - val_loss: 1012295360.0000\n",
      "Epoch 400/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200319360.0000 - val_loss: 1015963712.0000\n",
      "Epoch 401/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200458496.0000 - val_loss: 1019690176.0000\n",
      "Epoch 402/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 200224304.0000 - val_loss: 1019061248.0000\n",
      "Epoch 403/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 200241408.0000 - val_loss: 1016647488.0000\n",
      "Epoch 404/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 200359760.0000 - val_loss: 1018285632.0000\n",
      "Epoch 405/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 200142912.0000 - val_loss: 1015816192.0000\n",
      "Epoch 406/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200134544.0000 - val_loss: 1016170176.0000\n",
      "Epoch 407/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 200185088.0000 - val_loss: 1016765632.0000\n",
      "Epoch 408/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 200165632.0000 - val_loss: 1022370624.0000\n",
      "Epoch 409/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 199968528.0000 - val_loss: 1025374912.0000\n",
      "Epoch 410/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 199964816.0000 - val_loss: 1029353280.0000\n",
      "Epoch 411/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 199922736.0000 - val_loss: 1032290880.0000\n",
      "Epoch 412/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 200152144.0000 - val_loss: 1038194688.0000\n",
      "Epoch 413/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200048240.0000 - val_loss: 1038472384.0000\n",
      "Epoch 414/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 199814320.0000 - val_loss: 1044209408.0000\n",
      "Epoch 415/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 199853904.0000 - val_loss: 1048862272.0000\n",
      "Epoch 416/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 199886352.0000 - val_loss: 1051467776.0000\n",
      "Epoch 417/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200042448.0000 - val_loss: 1055851200.0000\n",
      "Epoch 418/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 199924656.0000 - val_loss: 1054232896.0000\n",
      "Epoch 419/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 199840192.0000 - val_loss: 1048626688.0000\n",
      "Epoch 420/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 199695104.0000 - val_loss: 1038788608.0000\n",
      "Epoch 421/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step - loss: 199863808.0000 - val_loss: 1024538048.0000\n",
      "Epoch 422/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 199755968.0000 - val_loss: 1015337792.0000\n",
      "Epoch 423/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 199813808.0000 - val_loss: 1010056448.0000\n",
      "Epoch 424/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 199788288.0000 - val_loss: 1008789952.0000\n",
      "Epoch 425/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 199776896.0000 - val_loss: 1009087488.0000\n",
      "Epoch 426/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 199760304.0000 - val_loss: 1010406976.0000\n",
      "Epoch 427/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 199690752.0000 - val_loss: 1014788800.0000\n",
      "Epoch 428/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 199719488.0000 - val_loss: 1021891264.0000\n",
      "Epoch 429/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 199557504.0000 - val_loss: 1026602432.0000\n",
      "Epoch 430/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 199514960.0000 - val_loss: 1031408128.0000\n",
      "Epoch 431/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 199713744.0000 - val_loss: 1038526656.0000\n",
      "Epoch 432/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 199519344.0000 - val_loss: 1040416832.0000\n",
      "Epoch 433/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 199535920.0000 - val_loss: 1040779840.0000\n",
      "Epoch 434/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 199485232.0000 - val_loss: 1038124544.0000\n",
      "Epoch 435/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 199468592.0000 - val_loss: 1033328192.0000\n",
      "Epoch 436/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 199458496.0000 - val_loss: 1029367232.0000\n",
      "Epoch 437/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 199328768.0000 - val_loss: 1020986048.0000\n",
      "Epoch 438/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 199231248.0000 - val_loss: 1008805824.0000\n",
      "Epoch 439/450\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 199287376.0000 - val_loss: 996653568.0000\n",
      "Epoch 440/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 199741184.0000 - val_loss: 981840640.0000\n",
      "Epoch 441/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 200080384.0000 - val_loss: 973934272.0000\n",
      "Epoch 442/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 200201872.0000 - val_loss: 972762624.0000\n",
      "Epoch 443/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 200188288.0000 - val_loss: 976577536.0000\n",
      "Epoch 444/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 199981584.0000 - val_loss: 982154944.0000\n",
      "Epoch 445/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 199714224.0000 - val_loss: 993362752.0000\n",
      "Epoch 446/450\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 199656832.0000 - val_loss: 1006181120.0000\n",
      "Epoch 447/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 199376528.0000 - val_loss: 1015893248.0000\n",
      "Epoch 448/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 199380496.0000 - val_loss: 1022650432.0000\n",
      "Epoch 449/450\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 199144912.0000 - val_loss: 1025100288.0000\n",
      "Epoch 450/450\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 199114768.0000 - val_loss: 1028810944.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17436f84610>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train,y=y_train,validation_data=(x_test,y_test),batch_size=128,epochs=450,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "123b32c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 998us/step\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70f6bbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 81)                3402      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 40)                3280      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 27)                1107      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 19)                532       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 100       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 18        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,443\n",
      "Trainable params: 8,443\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3d962ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 712us/step - loss: 365054496.0000\n"
     ]
    }
   ],
   "source": [
    "scores=model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87a96aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6512766292886345"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(r2_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86bd647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
